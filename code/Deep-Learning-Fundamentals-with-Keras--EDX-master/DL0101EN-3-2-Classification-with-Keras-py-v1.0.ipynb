{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL0101EN-3-2-Classification-with-Keras-py-v1.0.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"6OQ--3ermosk","colab_type":"text"},"cell_type":"markdown","source":["<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n","\n","<h1 align=center><font size = 5>Classification Models with Keras</font></h1>"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"PzdUbgCJmoss","colab_type":"text"},"cell_type":"markdown","source":["## Introduction"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"B5jinOS1mosw","colab_type":"text"},"cell_type":"markdown","source":["In this lab, we will learn how to use the Keras library to build models for classificaiton problems. We will use the popular MNIST dataset, a dataset of images, for a change. \n","\n","The <strong>MNIST database</strong>, short for Modified National Institute of Standards and Technology database, is a large database of handwritten digits that is commonly used for training various image processing systems.he database is also widely used for training and testing in the field of machine learning.\n","    \n","The MNIST database contains 60,000 training images and 10,000 testing images of digits written by high school students and employees of the United States Census Bureau.\n","\n","Also, this way, will get to compare how conventional neural networks compare to convolutional neural networks, that we will build in the next module."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"YA1VX-8lmos4","colab_type":"text"},"cell_type":"markdown","source":["## Table of Contents\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","<font size = 3>\n","\n","1. <a href=\"#item2\">Import Keras and Packages</a>      \n","2. <a href=\"#item3\">Build a Neural Network</a>     \n","3. <a href=\"#item4\">Train and Test the Network</a>     \n","</font>\n","</div>"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"pL_NiO3smotA","colab_type":"text"},"cell_type":"markdown","source":["## Import Keras and Packages"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"5V4nTtGlmotD","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.utils import to_categorical"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"FxiTum4Cmota","colab_type":"text"},"cell_type":"markdown","source":["Since we are dealing we images, let's also import the Matplotlib scripting layer in order to view the images."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"chOzNnn2mote","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"ykgVRA5Fmotn","colab_type":"text"},"cell_type":"markdown","source":["The Keras library conveniently includes the MNIST dataset as part of its API. You can check other datasets within the Keras library [here](https://keras.io/datasets/). \n","\n","So, let's load the MNIST dataset from the Keras library. The dataset is readily divided into a training set and a test set."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"q0rC2d7Zmotq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"00b939fe-c8b8-4ad2-af22-a89fb14338c6","executionInfo":{"status":"ok","timestamp":1555107136140,"user_tz":-180,"elapsed":2571,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["# import the data\n","from tensorflow.keras.datasets import mnist\n","\n","# read the data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"nC5SRymymot1","colab_type":"text"},"cell_type":"markdown","source":["Let's confirm the number of images in each set. According to the dataset's documentation, we should have 60000 images in X_train and 10000 images in the X_test."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"CoBcF8VCmot2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"39bcb276-b5d8-4d82-a5a8-1b26409e2bf1","executionInfo":{"status":"ok","timestamp":1555107136146,"user_tz":-180,"elapsed":793,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["X_train.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"dvN7WGn2mouB","colab_type":"text"},"cell_type":"markdown","source":["The first number in the output tuple is the number of images, and the other two numbers are the size of the images in datset. So, each image is 28 pixels by 28 pixels."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"f59lRBB_mouF","colab_type":"text"},"cell_type":"markdown","source":["Let's visualize the first image in the training set using Matplotlib's scripting layer."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"cOp0mmrMmouJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"outputId":"70f73c62-ceef-49ab-d205-4a753927afcf","executionInfo":{"status":"ok","timestamp":1555107141900,"user_tz":-180,"elapsed":666,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["plt.imshow(X_train[0])"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fd4952d2588>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiL\nHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGi\nwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53\nFd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k\n3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj\n1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uX\nu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T\n9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drI\nzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe\n9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzu\nvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2\nd/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2\nsv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oL\nb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8M\nOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX\n/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR\n2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930t\nuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr7\n4mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4\nfnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8s\nqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrc\nHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvL\nlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANB\nMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii\n/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cie\nvqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2\nuPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/\nlrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUz\nW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TT\nDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77\nrgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HD\nyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6\nFy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifr\nz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+e\nsL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH53\n73f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29m\nJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63\nrbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s\n2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/\nJredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rW\nhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6\nnP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uT\ndRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2\nS+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xm\nS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0x\nszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxa\nBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HSt\nAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWY\nRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii\n/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz\n22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v\n9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25\n+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LK\nAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vm\nmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV\n2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODY\nJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PN\nPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuT\ndLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4b\nn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"vNVxZPRHmouZ","colab_type":"text"},"cell_type":"markdown","source":["With conventional neural networks, we cannot feed in the image as input as is. So we need to flatten the images into one-dimensional vectors, each of size 1 x (28 x 28) = 1 x 784."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"Pc6TeaEXmouf","colab_type":"code","colab":{}},"cell_type":"code","source":["# flatten images into one-dimensional vector\n","\n","num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n","\n","X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n","X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"I91XXx8Ymou-","colab_type":"text"},"cell_type":"markdown","source":["Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"F7G1zUBumovC","colab_type":"code","colab":{}},"cell_type":"code","source":["# normalize inputs from 0-255 to 0-1\n","X_train = X_train / 255\n","X_test = X_test / 255"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"PGtStpVpmovJ","colab_type":"text"},"cell_type":"markdown","source":["Finally, before we start building our model, remember that for classification we need to divide our target variable into categories. We use the to_categorical function from the Keras Utilities package."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"ttUDODN9movL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"831c2bc7-6054-4b95-8a74-9f364d6bbc6b","executionInfo":{"status":"ok","timestamp":1555107158920,"user_tz":-180,"elapsed":620,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["# one hot encode outputs\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","num_classes = y_test.shape[1]\n","print(num_classes)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["10\n"],"name":"stdout"}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"kwIoeB-XmovX","colab_type":"text"},"cell_type":"markdown","source":["## Build a Neural Network"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"7qNbM6Spmovb","colab_type":"code","colab":{}},"cell_type":"code","source":["# define classification model\n","def classification_model():\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(num_pixels, activation='relu', input_shape=(num_pixels,)))\n","    model.add(Dense(100, activation='relu'))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    \n","    \n","    # compile model\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"d_mvKeMamovj","colab_type":"text"},"cell_type":"markdown","source":["## Train and Test the Network"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"scrolled":true,"id":"R-0ZAU0omovl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":732},"outputId":"d5325b90-2aaa-43b4-ce00-2b9eb19323a7","executionInfo":{"status":"ok","timestamp":1555107396034,"user_tz":-180,"elapsed":223080,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["# build the model\n","model = classification_model()\n","model.summary()\n","\n","# fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n","\n","# evaluate the model\n","scores = model.evaluate(X_test, y_test, verbose=0)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 784)               615440    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 100)               78500     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1010      \n","=================================================================\n","Total params: 694,950\n","Trainable params: 694,950\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 60000 samples, validate on 10000 samples\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/10\n"," - 23s - loss: 0.1838 - acc: 0.9435 - val_loss: 0.0918 - val_acc: 0.9714\n","Epoch 2/10\n"," - 22s - loss: 0.0773 - acc: 0.9750 - val_loss: 0.0924 - val_acc: 0.9715\n","Epoch 3/10\n"," - 22s - loss: 0.0532 - acc: 0.9824 - val_loss: 0.0752 - val_acc: 0.9778\n","Epoch 4/10\n"," - 22s - loss: 0.0416 - acc: 0.9863 - val_loss: 0.0754 - val_acc: 0.9769\n","Epoch 5/10\n"," - 22s - loss: 0.0317 - acc: 0.9895 - val_loss: 0.0714 - val_acc: 0.9816\n","Epoch 6/10\n"," - 22s - loss: 0.0276 - acc: 0.9910 - val_loss: 0.0675 - val_acc: 0.9823\n","Epoch 7/10\n"," - 22s - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0995 - val_acc: 0.9781\n","Epoch 8/10\n"," - 22s - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0735 - val_acc: 0.9823\n","Epoch 9/10\n"," - 23s - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0832 - val_acc: 0.9808\n","Epoch 10/10\n"," - 22s - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0832 - val_acc: 0.9802\n"],"name":"stdout"}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"mkD5ihSwmovx","colab_type":"text"},"cell_type":"markdown","source":["Let's print the accuracy and the corresponding error."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"e4buiJZxmovz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"281f2b95-c0fb-44d1-f5b1-862146adf0d7","executionInfo":{"status":"ok","timestamp":1555107396049,"user_tz":-180,"elapsed":17572,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))        "],"execution_count":11,"outputs":[{"output_type":"stream","text":["Accuracy: 0.9801999926567078% \n"," Error: 0.019800007343292236\n"],"name":"stdout"}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"cmxBhRx8mowA","colab_type":"text"},"cell_type":"markdown","source":["Just running 10 epochs could actually take over 2 minutes. But enjoy the results as they are getting generated."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"w89oGFkomowH","colab_type":"text"},"cell_type":"markdown","source":["Sometimes, you cannot afford to retrain your model everytime you want to use it, especially if you are limited on computational resources and training your model can take a long time. Therefore, with the Keras library, you can save your model after training. To do that, we use the save method."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"szV_A0JVmowJ","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save('classification_model.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"FXEFPwqzmowR","colab_type":"text"},"cell_type":"markdown","source":["Since our model contains multidimensional arrays of data, then models are usually saved as .h5 files."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"GYH_dWlfmowU","colab_type":"text"},"cell_type":"markdown","source":["When you are ready to use your model again, you use the load_model function from <strong>keras.models</strong>."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"npk_xfICmowa","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"execution_count":0,"outputs":[]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"aQVFOKlKmowr","colab_type":"code","colab":{}},"cell_type":"code","source":["pretrained_model = load_model('classification_model.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aNdX5ZJDoIb5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":321},"outputId":"7c558baf-b424-4ce4-9db4-73dc17dfa271","executionInfo":{"status":"ok","timestamp":1555107609661,"user_tz":-180,"elapsed":1226,"user":{"displayName":"Akis Karagiannis","photoUrl":"https://lh3.googleusercontent.com/-zwou8zxxCY8/AAAAAAAAAAI/AAAAAAAAAK0/Lzb-ypOt4MY/s64/photo.jpg","userId":"03616904052675675352"}}},"cell_type":"code","source":["classifications = pretrained_model.predict(X_test)\n","print(classifications[0])\n","plt.imshow(X_test[0].reshape(28, 28))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[8.7116481e-16 1.4805509e-11 1.3076905e-12 1.8401556e-11 5.4394107e-18\n"," 3.5289914e-17 2.0347827e-21 1.0000000e+00 7.2279226e-14 3.6030953e-12]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fd48eb23780>"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"E9LdIp1_mowy","colab_type":"text"},"cell_type":"markdown","source":["### Thank you for completing this lab!\n","\n","This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!"]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"FFeyTGAOmow4","colab_type":"text"},"cell_type":"markdown","source":["This notebook is part of a course on **edX** called *Deep Learning Fundamentals with Keras*. If you accessed this notebook outside the course, you can take this course online by clicking [here](http://cocl.us/DL0101EN_edX_Week3_LAB2)."]},{"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false},"id":"YT7kevo2mow5","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","\n","Copyright &copy; 2018 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."]}]}